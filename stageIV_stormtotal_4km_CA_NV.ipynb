{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2843c2-8000-4409-ad3a-df32273c97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to compare basic meteorological parameters between WRF simulations and ERA5 data\n",
    "# Some of the following imports are not used right now, but will retain for future flexibility\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install geopandas\n",
    " \n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.prepared import prep\n",
    "import csv\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "import matplotlib.cbook as cbook\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import *\n",
    "from pylab import *\n",
    "import pygrib\n",
    "import pyproj\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.interpolate import griddata\n",
    "from siphon.catalog import TDSCatalog\n",
    "from siphon.http_util import session_manager\n",
    "from datetime import datetime, timedelta\n",
    "from xarray.backends import NetCDF4DataStore\n",
    "from netCDF4 import Dataset\n",
    "import metpy as metpy\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.plots import ctables\n",
    "from metpy.units import units\n",
    "from metpy.plots import add_metpy_logo, add_timestamp\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import scipy.ndimage as ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import interpolate\n",
    "from scipy.stats import pearsonr\n",
    "import cartopy.crs as crs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "from cartopy import config\n",
    "import wrf\n",
    "from wrf import (to_np, interplevel, geo_bounds, getvar, smooth2d, get_cartopy, cartopy_xlim,\n",
    "                 cartopy_ylim, latlon_coords)\n",
    "# Download and add the states and coastlines\n",
    "states = NaturalEarthFeature(category=\"cultural\", scale=\"50m\",\n",
    "                          facecolor=\"none\", name=\"admin_1_states_provinces_shp\")\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b030b41-0fd9-408f-81fb-3e3fd90d9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Stage IV', 'Thompson', 'Thompson AA', 'WSM6', 'WDM6',\n",
    "          'P3', 'P3 2X', 'P3 2nd', 'P3 3-mom', 'Ishmael', 'NTU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d253b5a-3658-42d6-850b-9a877d60450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current file\n",
    "wrf_file = \"/scratch/sawyer/wwrf/2017-01-09/ctrl/wrfout_d02_2017-01-09_12:00:00\"\n",
    "datafiles = (glob.glob(wrf_file))\n",
    "ncfile = Dataset(datafiles[0])\n",
    "#lu_index = ncfile['LU_INDEX'][0,:,:]\n",
    "#print(lu_index)\n",
    "rainc = getvar(ncfile, \"RAINC\")\n",
    "wrf_lats, wrf_lons = latlon_coords(rainc)\n",
    "## WWRF longitude fix ######\n",
    "new_lons =np.where(wrf_lons > 0, wrf_lons - 360, wrf_lons)\n",
    "\n",
    "cart_proj = get_cartopy(rainc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac17149-9d58-4be4-ba38-7e638a8bda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = '/scratch/sawyer/stage_IV_storm_tot/2017-01-09/72h_total'\n",
    "\n",
    "all_files = os.listdir(directory_path)\n",
    "stageiv_storm_total = np.zeros((881, 1121))\n",
    "for file in all_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    \n",
    "    with pygrib.open(file_path) as grb:\n",
    "        # Assuming the first message contains the precipitation data\n",
    "        # Adjust as necessary based on the structure of your GRIB files\n",
    "        message = grb.message(1)\n",
    "        #print(message)\n",
    "        data = message.values\n",
    "        #print(data.shape)\n",
    "        # Extract latitudes and longitudes\n",
    "        stageiv_lats, stageiv_lons = message.latlons()\n",
    "\n",
    "        stageiv_storm_total += data\n",
    "# Use np.where to replace values greater than 1000 with 0\n",
    "stageiv_storm_total = np.where(stageiv_storm_total > 1000, np.nan, stageiv_storm_total)\n",
    "print(stageiv_storm_total.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd06ce0-24d8-41e3-8eb4-487e4f3a935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set limits for latitude and longitude to focus on California\n",
    "# Rough bounds: (32.5 to 42 N) and (-124.5 to -114 W)\n",
    "lon_min, lon_max = -124.5, -114\n",
    "lat_min, lat_max = 32.5, 42.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "ax.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.25, edgecolor='black')\n",
    "ax.coastlines('50m', linewidth=0.6, color='black')\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle=':', linewidth=0.5)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "gl.top_labels=False # suppress top labels\n",
    "gl.bottom_labels=False\n",
    "gl.right_labels=False \n",
    "gl.left_labels=False\n",
    "\n",
    "contours = plt.contourf(to_np(stageiv_lons), to_np(stageiv_lats), to_np(stageiv_storm_total), cmap='YlGnBu', levels=np.arange(25, 400, 25), transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(contours, ax=ax, orientation=\"vertical\", pad=.03, shrink=.8, aspect=50)\n",
    "cbar.set_label(\"Precipitation (mm)\", fontsize = 12)\n",
    "ax.set_title(\"Stage IV 72 h Storm Total\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb98e77-b484-4b9d-a6b4-06d05bc2c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rain_total(current_file_path, initial_file_path):\n",
    "    # Load current file\n",
    "    \n",
    "    current_datafiles = (glob.glob(current_file_path))\n",
    "    ncfile_current = Dataset(current_datafiles[0])\n",
    "    land_mask = ncfile_current['LANDMASK'][0,:,:]\n",
    "    \n",
    "\n",
    "    rainc_current = getvar(ncfile_current, \"RAINC\")\n",
    "    rainnc_current = getvar(ncfile_current, \"RAINNC\")\n",
    "    rain_final = (rainnc_current + rainc_current) * land_mask\n",
    "    # Apply the land mask on rain data\n",
    "  \n",
    "    # Load initial file\n",
    "    initial_datafiles = (glob.glob(initial_file_path))\n",
    "    ncfile_initial = Dataset(initial_datafiles[0])\n",
    "    rainc_initial = getvar(ncfile_initial, \"RAINC\")\n",
    "    rainnc_initial = getvar(ncfile_initial, \"RAINNC\")\n",
    "    rain_initial = (rainnc_initial + rainc_initial) * land_mask\n",
    "    # Apply the land mask on rain data\n",
    " \n",
    "    \n",
    "    return rain_final - rain_initial\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    x = (predictions - targets) ** 2\n",
    "    x_mean = np.nanmean(x)\n",
    "    rmserror = np.sqrt(x_mean)\n",
    "    return rmserror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72adcf4-205a-4d19-b092-60c3f6571295",
   "metadata": {},
   "outputs": [],
   "source": [
    "thompson_final = \"/scratch/sawyer/wwrf/2017-01-09/ctrl/wrfout_d02_2017-01-09_12:00:00\"\n",
    "thompson_init = \"/scratch/sawyer/wwrf/2017-01-09/ctrl/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "wsm6_final = \"/scratch/sawyer/wwrf/2017-01-09/wsm6/wrfout_d02_2017-01-09_12:00:00\"\n",
    "wsm6_init = \"/scratch/sawyer/wwrf/2017-01-09/wsm6/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "wdm6_final = \"/scratch/sawyer/wwrf/2017-01-09/wdm6/wrfout_d02_2017-01-09_12:00:00\"\n",
    "wdm6_init = \"/scratch/sawyer/wwrf/2017-01-09/wdm6/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "ishmael_final = \"/scratch/sawyer/wwrf/2017-01-09/ishmael/wrfout_d02_2017-01-09_12:00:00\"\n",
    "ishmael_init = \"/scratch/sawyer/wwrf/2017-01-09/ishmael/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "p3_final = \"/scratch/sawyer/wwrf/2017-01-09/p3_1-cat/wrfout_d02_2017-01-09_12:00:00\"\n",
    "p3_init = \"/scratch/sawyer/wwrf/2017-01-09/p3_1-cat/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "p3_2x_final = \"/scratch/sawyer/wwrf/2017-01-09/p3_2x_cloud/wrfout_d02_2017-01-09_12:00:00\"\n",
    "p3_2x_init = \"/scratch/sawyer/wwrf/2017-01-09/p3_2x_cloud/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "p3_3mom_final = \"/scratch/sawyer/wwrf/2017-01-09/p3_3mom/wrfout_d02_2017-01-09_12:00:00\"\n",
    "p3_3mom_init = \"/scratch/sawyer/wwrf/2017-01-09/p3_3mom/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "p3_2nd_final = \"/scratch/sawyer/wwrf/2017-01-09/p3_2nd/wrfout_d02_2017-01-09_12:00:00\"\n",
    "p3_2nd_init = \"/scratch/sawyer/wwrf/2017-01-09/p3_2nd/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "thompson_aa_final = \"/scratch/sawyer/wwrf/2017-01-09/thompson_aa_38/wrfout_d02_2017-01-09_12:00:00\"\n",
    "thompson_aa_init = \"/scratch/sawyer/wwrf/2017-01-09/thompson_aa_38/wrfout_d02_2017-01-06_12:00:00\"\n",
    "\n",
    "ntu_final = \"/scratch/sawyer/wwrf/2017-01-09/ntu/wrfout_d02_2017-01-09_12:00:00\"\n",
    "ntu_init = \"/scratch/sawyer/wwrf/2017-01-09/ntu/wrfout_d02_2017-01-06_12:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e7809-864b-440d-b828-8f883a7a6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thompson_storm_total = compute_rain_total(thompson_final,thompson_init)\n",
    "\n",
    "thompson_aa_storm_total = compute_rain_total(thompson_aa_final,thompson_aa_init)\n",
    "\n",
    "wsm6_storm_total = compute_rain_total(wsm6_final,wsm6_init)\n",
    "\n",
    "wdm6_storm_total = compute_rain_total(wdm6_final,wdm6_init)\n",
    "\n",
    "p3_storm_total = compute_rain_total(p3_final,p3_init)\n",
    "\n",
    "p3_2x_storm_total = compute_rain_total(p3_2x_final,p3_2x_init)\n",
    "\n",
    "p3_2nd_storm_total = compute_rain_total(p3_2nd_final,p3_2nd_init)\n",
    "\n",
    "p3_3mom_storm_total = compute_rain_total(p3_3mom_final,p3_3mom_init)\n",
    "\n",
    "ishamel_storm_total = compute_rain_total(ishmael_final,ishmael_init)\n",
    "\n",
    "ntu_storm_total = compute_rain_total(ntu_final,ntu_init)\n",
    "#print(thompson_storm_total.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec04f3-fd43-4716-a27e-2cc9113bc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrf_totals = [thompson_storm_total,thompson_aa_storm_total,wsm6_storm_total,\n",
    "            wdm6_storm_total,p3_storm_total,p3_2x_storm_total,p3_2nd_storm_total,\n",
    "           p3_3mom_storm_total,ishamel_storm_total, ntu_storm_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d8698-5345-4d89-8a78-9a5f47455fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending all the interpolated storm total 3 km wrf grids to a list with PRISM storm total\n",
    "interp_list = [stageiv_storm_total]\n",
    "\n",
    "for i in wrf_totals:\n",
    "    # Define the source CRS (your PRISM data's original projection)\n",
    "    target_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "    # Define the target CRS as WGS 84\n",
    "    source_proj = pyproj.Proj(proj=\"latlong\", datum=\"WGS84\")\n",
    "\n",
    "    # Transform the WRF coordinates\n",
    "    lon_new, lat_new = pyproj.transform(source_proj, target_proj, new_lons,wrf_lats)\n",
    "    #print(lon_new)\n",
    "\n",
    "    # Assuming wrf_lon and wrf_lat are the 2D arrays representing the longitude and latitude grids of your WRF data.\n",
    "    points_wrf = (lon_new.ravel(), lat_new.ravel()) \n",
    "    #print(points_prism)# Reprojected PRISM coordinates\n",
    "    values_wrf = to_np(i).ravel()  # PRISM data values\n",
    "\n",
    "    data_wrf = griddata(points_wrf, values_wrf, (stageiv_lons,stageiv_lats), method='linear')\n",
    "    interp_list.append(data_wrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6241793-6d8c-49f0-99d8-328aa2168408",
   "metadata": {},
   "outputs": [],
   "source": [
    "stageiv_data = interp_list[0]\n",
    "#wrf_data = interp_list[1:]\n",
    "#print(stageiv_data[stageiv_data<89991])\n",
    "\n",
    "# Set limits for latitude and longitude to focus on California\n",
    "# Rough bounds: (32.5 to 42 N) and (-124.5 to -114 W)\n",
    "lon_min, lon_max = -124.5, -114\n",
    "lat_min, lat_max = 32.5, 42.5\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "ax.add_feature(cfeature.STATES.with_scale('50m'), linewidth=0.25, edgecolor='black')\n",
    "ax.coastlines('50m', linewidth=0.6, color='black')\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle=':', linewidth=0.5)\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False)\n",
    "gl.top_labels=False # suppress top labels\n",
    "gl.bottom_labels=False\n",
    "gl.right_labels=False \n",
    "gl.left_labels=False\n",
    "\n",
    "contours = plt.contourf(to_np(stageiv_lons), to_np(stageiv_lats), to_np(stageiv_data), cmap='YlGnBu', levels=np.arange(25, 400, 25), transform=ccrs.PlateCarree())\n",
    "cbar = plt.colorbar(contours, ax=ax, orientation=\"vertical\", pad=.03, shrink=.8, aspect=50)\n",
    "cbar.set_label(\"Precipitation (mm)\", fontsize = 12)\n",
    "ax.set_title(\"Stage IV 72 h Storm Total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f536b4-105b-4682-83ac-4cc85bbb67da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load US states shapefile\n",
    "states = gpd.read_file('/scratch/sawyer/geopandas/ne_110m_admin_1_states_provinces.shp')\n",
    "\n",
    "# Get combined shape of California and Nevada\n",
    "combined_shape = states[states.name.isin(['California', 'Nevada'])].unary_union\n",
    "prepared_shape = prep(combined_shape)  # Prepare the geometry for faster operations\n",
    "\n",
    "def in_combined_shape(lats, lons):\n",
    "    \"\"\"Check if coordinates are inside the combined shape of California and Nevada.\"\"\"\n",
    "    point = Point(lons, lats)\n",
    "    return prepared_shape.contains(point)\n",
    "\n",
    "# Vectorize the function\n",
    "vectorized_contains = np.vectorize(in_combined_shape)\n",
    "\n",
    "# Assuming stageiv_lons and stageiv_lats are 1D arrays or flattened arrays\n",
    "ca_nv_stageiv = vectorized_contains(stageiv_lats,stageiv_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7135785-525d-478c-9cea-28df7211c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_nv_data = []\n",
    "\n",
    "for precip_value in interp_list:\n",
    "     # now placing the California mask over the new Stage IV data\n",
    "    state_mask = np.where(ca_nv_stageiv, precip_value, np.nan)\n",
    "    ca_nv_data.append(state_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed900c77-c4f8-4f06-9c77-11914ca972f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_bold = FontProperties()\n",
    "font_bold.set_weight('bold')\n",
    "# Create 10 subplots\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(20, 12),\n",
    "                        subplot_kw={'projection': ccrs.LambertConformal()}) #ccrs.PlateCarree()\n",
    "axs = axs.ravel()  # Flatten axs to loop over\n",
    "# Gridlines' latitudes and longitudes\n",
    "lats = np.arange(32.5, 43, 2)  # Example: ticks every 2 degrees. Adjust as needed.\n",
    "lons = np.arange(-125, -114, 2)\n",
    "for i, ax in enumerate(axs[:-1]):\n",
    "    #print(titles[i])\n",
    "    ax.set_extent([-123,-113,32.5,42.5])\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=1.0, edgecolor='black')  # Add coastlines\n",
    "    ax.add_feature(cfeature.STATES, linewidth=1.0, edgecolor='black')\n",
    "    # Use gridlines and customize them to look like ticks\n",
    "    #gl = ax.gridlines(draw_labels=False, linewidth=1, color='black', alpha=0.5, linestyle='--', xlocs=lons, ylocs=lats)\n",
    "    #gl.xlabels_bottom = True\n",
    "    #gl.ylabels_left = True\n",
    "    #gl.xlines = True\n",
    "    #gl.ylines = True\n",
    "    #gl.linewidth = .5\n",
    "    #gl.color = 'black'\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    ax.set_title(titles[i], fontweight='bold')\n",
    "    # Plot filled contour\n",
    "    cp = ax.contourf(to_np(stageiv_lons),to_np(stageiv_lats), to_np(ca_nv_data[i]), cmap='YlGnBu', \n",
    "                     levels=np.arange(25, 400, 25), transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "# Turn off the last subplot\n",
    "axs[-1].axis('off')\n",
    "# Add a single colorbar at the bottom of the figure\n",
    "cbar_ax = fig.add_axes([0.15, 0.08, 0.7, 0.02])  # Adjust these dimensions to fit the colorbar nicely\n",
    "cbar = fig.colorbar(cp, cax=cbar_ax, orientation='horizontal', label=\"Precipitation (mm)\")\n",
    "cbar.set_label(\"Precipitation (mm)\", fontproperties=font_bold)\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15)  # Make space for the colorbar\n",
    "\n",
    "plt.savefig('StormTotal_QPF_StageIV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7764a6-e61d-45e2-b714-83d1483c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "stageiv = ca_nv_data[0]\n",
    "diff_fields = []\n",
    "for precip_value in ca_nv_data[1:]:\n",
    "    # Compute the difference\n",
    "    diff_fields.append(stageiv - precip_value)\n",
    "    \n",
    "print(len(diff_fields)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c698aea-56b9-4b9c-890a-f4a7483bba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "stageiv_sum = np.nanmean(stageiv)\n",
    "print(stageiv_sum)\n",
    "bias_errors = []\n",
    "for precip_data in ca_nv_data[1:]:\n",
    "    \n",
    "    total = np.nanmean(precip_data)\n",
    "    bias = round((total-stageiv_sum),2)\n",
    "    bias_errors.append(bias)\n",
    "    #print(total)\n",
    "    #print('bias: ', bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4668fb-0dbd-4279-9601-4f787a292afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_errors = []\n",
    "for precip_data in ca_nv_data[1:]:\n",
    "    errors = rmse(precip_data,stageiv)\n",
    "    rain_errors.append(round(errors,2))\n",
    "    \n",
    "wrf_titles = ['Thompson', 'Thompson AA', 'WSM6', 'WDM6',\n",
    "          'P3', 'P3 2X', 'P3 2nd', 'P3 3-mom', 'Ishmael', 'NTU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91643e29-f616-41bd-962c-8514950e40f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rain_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f85e4-ae02-4d4c-942c-7b7434c37f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 subplots\n",
    "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(20, 12),\n",
    "                        subplot_kw={'projection': ccrs.LambertConformal()})\n",
    "axs = axs.ravel()  # Flatten axs to loop over\n",
    "# Gridlines' latitudes and longitudes\n",
    "lats = np.arange(32, 43, 2)  # Example: ticks every 2 degrees. Adjust as needed.\n",
    "lons = np.arange(-125, -114, 2)\n",
    "#levels = np.arange(-200,200,50)\n",
    "levels = np.arange(-300, 200, 25)\n",
    "\n",
    "norm = TwoSlopeNorm(vmin=levels.min(), vcenter=0, vmax=levels.max())  # This normalizes the colormap around 0\n",
    "for i, ax in enumerate(axs):\n",
    "    #print(titles[i])\n",
    "    ax.set_extent([-125,-115,32,42])\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.8, edgecolor='black')  # Add coastlines\n",
    "    ax.add_feature(cfeature.STATES, linewidth=0.8, edgecolor='black')\n",
    "    # Use gridlines and customize them to look like ticks\n",
    "    #gl = ax.gridlines(draw_labels=False, linewidth=1, color='black', alpha=0.5, linestyle='--', xlocs=lons, ylocs=lats)\n",
    "    #gl.xlabels_bottom = True\n",
    "    #gl.ylabels_left = True\n",
    "    #gl.xlines = True\n",
    "    #gl.ylines = True\n",
    "    #gl.linewidth = .5\n",
    "    #gl.color = 'black'\n",
    "\n",
    "    # Set the title for each subplot\n",
    "    ax.set_title(f\"{wrf_titles[i]} \\nRMSE = {rain_errors[i]} mm\\nBias = {bias_errors[i]} mm\", fontweight='bold', fontsize=14,loc='left')\n",
    "    #ax.set_title(f\"RMSE = {rain_errors[i]} mm\", fontweight='bold',fontsize=10, loc='right')\n",
    "    # Plot filled contour\n",
    "    cp = ax.contourf(to_np(stageiv_lons),to_np(stageiv_lats), diff_fields[i],levels=levels, cmap='RdBu', norm=norm,transform=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    \n",
    "\n",
    "# Add a single colorbar at the bottom of the figure\n",
    "cbar_ax = fig.add_axes([0.15, 0.08, 0.7, 0.02])  # Adjust these dimensions to fit the colorbar nicely\n",
    "cbar = fig.colorbar(cp, cax=cbar_ax, orientation='horizontal', label=\"Precipitation (mm)\")\n",
    "# Set the ticks explicitly\n",
    "cbar.set_ticks(levels)\n",
    "#cbar.set_label(fontproperties=font_bold)\n",
    "# Adjust layout\n",
    "#fig.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.15, hspace=0.3)  # Make space for the colorbar\n",
    "\n",
    "plt.savefig('Staveiv_StormTotal_Diff_Fields_QPF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3da9e1-5868-4d8b-873c-eddfc3dad2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrf = to_np(ca_nv_data[1:])\n",
    "#valid_indices = ~np.isnan(prism) & ~np.isnan(wrf)\n",
    "corr = []\n",
    "corr_sqrd = []\n",
    "for i in wrf:\n",
    "    # Calculate valid indices for the current pair\n",
    "    valid_indices = ~np.isnan(stageiv) & ~np.isnan(i)\n",
    "    \n",
    "    correlation_coefficient, _ = pearsonr(i[valid_indices], stageiv[valid_indices])\n",
    "    corr_sq = correlation_coefficient**2\n",
    "    corr_sqrd.append(round(corr_sq,4))\n",
    "    correlation_coefficient = round(correlation_coefficient,4)\n",
    "    #print(correlation_coefficient)\n",
    "    corr.append(correlation_coefficient)\n",
    "print(corr_sqrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecf874-07ab-4758-a557-366c7ed15ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=5, figsize=(20, 12))\n",
    "axs = axs.ravel()\n",
    "\n",
    "corr = []\n",
    "corr_sqrd = []\n",
    "# Determine global min and max for y-axis\n",
    "global_min = np.nanmin([np.nanmin(data) for data in wrf])\n",
    "global_max = np.nanmax([np.nanmax(data) for data in wrf]\n",
    "for i, ax in enumerate(axs):\n",
    "    current_wrf_data = wrf[i]\n",
    "    \n",
    "    valid_indices = ~np.isnan(stageiv) & ~np.isnan(current_wrf_data)\n",
    "    filtered_stageiv = np.array(stageiv)[valid_indices]\n",
    "    filtered_wrf_data = np.array(current_wrf_data)[valid_indices]\n",
    "\n",
    "    # Scatter plot\n",
    "    ax.scatter(filtered_stageiv, filtered_wrf_data, alpha=0.5, label='Data')\n",
    "\n",
    "    # Line of best fit\n",
    "    slope, intercept = np.polyfit(filtered_stageiv, filtered_wrf_data, 1)\n",
    "    ax.plot(filtered_stageiv, slope*filtered_stageiv + intercept, color='red', label=f'Fit: y={slope:.2f}x + {intercept:.2f}')\n",
    "\n",
    "    # Calculate Pearson correlation coefficient\n",
    "    correlation_coefficient, _ = pearsonr(filtered_stageiv, filtered_wrf_data)\n",
    "    corr.append(correlation_coefficient)\n",
    "    corr_sqrd.append(correlation_coefficient**2)\n",
    "    \n",
    "    # Add legend entry for correlation coefficient and r^2\n",
    "    #ax.legend([f'Corr: {correlation_coefficient:.2f}', f'$r^2$: {correlation_coefficient**2:.2f}'])\n",
    "    #ax.legend([f'Corr: {correlation_coefficient:.2f}', f'$r^2$: {correlation_coefficient**2:.2f}'], fontsize=13,loc='upper left')\n",
    "    # Add text for correlation coefficient and r^2 in the upper left corner\n",
    "    ax.text(0.05, 0.95, f'CORR: {correlation_coefficient:.2f}', transform=ax.transAxes, verticalalignment='top', fontsize=14,fontweight='bold')\n",
    "    ax.text(0.05, 0.88, f'$r^2$: {correlation_coefficient**2:.2f}', transform=ax.transAxes, verticalalignment='top', fontsize=14,fontweight='bold')\n",
    "   # Add labels \n",
    "    ax.set_xlabel('Stage IV', fontsize = 14,fontweight='bold')\n",
    "    ax.set_ylabel(f'{wrf_titles[i]}', fontsize = 14,fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ad671-fa5e-4eeb-9fbf-769c68f77814",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"your_data.csv\"\n",
    "\n",
    "# Sample data as a list of dictionaries\n",
    "data = [\n",
    "    {\"Ensemble member\": 'NTU', \"Day 1 RMSE\": 6.48, \"Day 2 RMSE\": 0.6, \"Day 3 RMSE\": 0.7, \"Storm Total RMSE\": 2.0},\n",
    "    {\"Ensemble member\": 'Thompson, \"Day 1 RMSE\": 4.76, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},\n",
    "    {\"Ensemble member\": 'WSM6, \"Day 1 RMSE\": 5.67, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},# Add more data for other ensemble members\n",
    "{\"Ensemble member\": 'WDM6, \"Day 1 RMSE\": 6.78, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},\n",
    "{\"Ensemble member\": 'P3, \"Day 1 RMSE\": 5.12, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},\n",
    "{\"Ensemble member\": 'P3 2nd , \"Day 1 RMSE\": 4.81, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},\n",
    "{\"Ensemble member\": 'Ishmael, \"Day 1 RMSE\": 5.46, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},\n",
    "{\"Ensemble member\": 'Thompson AA, \"Day 1 RMSE\": 4.72, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},\n",
    "{\"Ensemble member\": 'P3 2x Cloud, \"Day 1 RMSE\": 4.76, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},\n",
    "{\"Ensemble member\": 'P3 3mom, \"Day 1 RMSE\": 4.76, \"Day 2 RMSE\": 0.7, \"Day 3 RMSE\": 0.8, \"Storm Total RMSE\": 2.1},]\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "file_exists = False\n",
    "try:\n",
    "    with open(csv_file_path, \"r\") as file:\n",
    "        # If the file exists, read it to check for existing data\n",
    "        file_exists = True\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file_path, \"a\", newline=\"\") as file:\n",
    "    fieldnames = [\"Ensemble member\", \"Day 1 RMSE\", \"Day 2 RMSE\", \"Day 3 RMSE\", \"Storm Total RMSE\"]\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write the header row if the file is newly created\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "    \n",
    "    # Write data for each ensemble member\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Data has been appended to the CSV file.\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MEA443",
   "language": "python",
   "name": "mea443"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
